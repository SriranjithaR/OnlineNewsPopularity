--KBest
Applying SelectKBest
Score  for  1  features :  0.541549074945
Score  for  2  features :  0.563813107557
Score  for  3  features :  0.571338977736
Score  for  4  features :  0.568359987457
Score  for  5  features :  0.575258701787
Score  for  6  features :  0.572122922546
Score  for  7  features :  0.584979617435
Score  for  8  features :  0.58764502979
Score  for  9  features :  0.596268422703
Score  for  10  features :  0.597993101286
Score  for  11  features :  0.607714016933
Score  for  12  features :  0.613985575415
Score  for  13  features :  0.608184383819
Score  for  14  features :  0.605675760426
Score  for  15  features :  0.61429915334
Score  for  16  features :  0.619002822201
Score  for  17  features :  0.610222640326
Score  for  18  features :  0.625431169646
Score  for  19  features :  0.626215114456
Score  for  20  features :  0.62119786767
Score  for  21  features :  0.625587958608
Score  for  22  features :  0.624333646911
Score  for  23  features :  0.617591721543
Score  for  24  features :  0.618846033239
Score  for  25  features :  0.62731263719
Score  for  26  features :  0.625274380684
Score  for  27  features :  0.626685481342
Score  for  28  features :  0.622295390405
Score  for  29  features :  0.623549702101
Score  for  30  features :  0.62041392286
Score  for  31  features :  0.623706491063
Score  for  32  features :  0.627626215114
Score  for  33  features :  0.629507682659
Score  for  34  features :  0.617748510505
Score  for  35  features :  0.624490435873
Score  for  36  features :  0.630291627469
Score  for  37  features :  0.626371903418
Score  for  38  features :  0.633897773597
Score  for  39  features :  0.630448416431
Score  for  40  features :  0.629037315773
Score  for  41  features :  0.63185951709
Score  for  42  features :  0.631545939166
Score  for  43  features :  0.630134838507
Score  for  44  features :  0.63797428661
Score  for  45  features :  0.634211351521
Score  for  46  features :  0.629194104735
Score  for  47  features :  0.635779241141
Score  for  48  features :  0.629350893697
Score  for  49  features :  0.634524929445
Score  for  50  features :  0.628253370963
Score  for  51  features :  0.625587958608
Score  for  52  features :  0.630761994356
Score  for  53  features :  0.629350893697
Score  for  54  features :  0.619473189087
Score  for  55  features :  0.63640639699
Score  for  56  features :  0.625431169646
Score  for  57  features :  0.627155848228
Score  for  58  features :  0.629194104735
Score  for  59  features :  0.628880526811
Max score was obtained for :  44  features
Score :  0.623549702101
Precision recall f-score support :  (array([ 0.62838993,  0.64201313]), array([ 0.75870206,  0.49096386]), array([ 0.68742483,  0.5564195 ]), array([3390, 2988], dtype=int64))

Manual  2  fold cross validation score
cross_validation.py:21: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  x_cv = x_train[sIndex:fIndex]
cross_validation.py:22: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  y_cv = y_train[sIndex:fIndex]
cross_validation.py:24: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  x_t = np.concatenate((x_train[0:max(0,sIndex)],x_train[fIndex:n]),axis=0);
cross_validation.py:25: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  y_t = np.concatenate((y_train[0:max(0,sIndex)],y_train[fIndex:n]),axis=0);
0.587615943846
0.617385309601

Checking with inbuilt function
[ 0.59852093  0.61550514]

Manual parameter tuning
Tuning no. of estimators
Score for  10 : 0.627469426152
Score for  20 : 0.637660708686
Score for  30 : 0.655064283474
Score for  40 : 0.656945751019
Score for  50 : 0.666823455629
Score for  60 : 0.659924741298
Score for  70 : 0.659767952336
Score for  80 : 0.668234556287
Score for  90 : 0.661806208843
Score for  100 : 0.656788962057
Score for  110 : 0.666666666667
Best parameter :  80

Tuning max depth
Score for  5 : 0.647224835372
Score for  10 : 0.664314832236
Score for  15 : 0.671997491377
Score for  20 : 0.662903731577
Score for  25 : 0.664158043274
Best parameter :  15

Max score obtained using decision tree :  0.671997491377

ROC curve Area = 0.722810711874
AUC for CV:
ROC fold 0(area = 0.678776934098)
ROC fold 1(area = 0.723630611008)
ROC fold 2(area = 0.723896142733)
ROC fold 3(area = 0.719504779658)
ROC fold 4(area = 0.74587852283)
ROC fold 5(area = 0.733738753439)

--PCA
Applying PCA
Score  for  1  features :  0.52289118846
Score  for  2  features :  0.539354029476
Score  for  3  features :  0.542333019755
Score  for  4  features :  0.552994669175
Score  for  5  features :  0.550642834744
Score  for  6  features :  0.58309814989
Score  for  7  features :  0.580589526497
Score  for  8  features :  0.578394481029
Score  for  9  features :  0.587958607714
Score  for  10  features :  0.580589526497
Score  for  11  features :  0.588742552524
Score  for  12  features :  0.589056130448
Score  for  13  features :  0.602069614299
Score  for  14  features :  0.593446221386
Score  for  15  features :  0.597522734399
Score  for  16  features :  0.596268422703
Score  for  17  features :  0.596738789589
Score  for  18  features :  0.608184383819
Score  for  19  features :  0.598777046096
Score  for  20  features :  0.601442458451
Score  for  21  features :  0.597522734399
Score  for  22  features :  0.602696770147
Score  for  23  features :  0.61429915334
Score  for  24  features :  0.620100344936
Score  for  25  features :  0.623079335215
Score  for  26  features :  0.621825023518
Score  for  27  features :  0.624647224835
Score  for  28  features :  0.622608968329
Score  for  29  features :  0.624647224835
Score  for  30  features :  0.624490435873
Score  for  31  features :  0.623706491063
Score  for  32  features :  0.621825023518
Score  for  33  features :  0.627626215114
Score  for  34  features :  0.62731263719
Score  for  35  features :  0.624960802759
Score  for  36  features :  0.618218877391
Score  for  37  features :  0.629821260583
Score  for  38  features :  0.616337409846
Score  for  39  features :  0.621825023518
Score  for  40  features :  0.618532455315
Score  for  41  features :  0.623706491063
Score  for  42  features :  0.625117591722
Score  for  43  features :  0.629507682659
Score  for  44  features :  0.61665098777
Score  for  45  features :  0.631545939166
Score  for  46  features :  0.621041078708
Score  for  47  features :  0.616023831922
Score  for  48  features :  0.623549702101
Score  for  49  features :  0.618218877391
Score  for  50  features :  0.618846033239
Score  for  51  features :  0.622765757291
Score  for  52  features :  0.616494198808
Score  for  53  features :  0.613828786453
Score  for  54  features :  0.623392913139
Score  for  55  features :  0.617278143619
Score  for  56  features :  0.605989338351
Score  for  57  features :  0.619159611163
Score  for  58  features :  0.628566948887
Score  for  59  features :  0.612888052681
Max score was obtained for :  45  features
Score :  0.624490435873
Precision recall f-score support :  (array([ 0.62190548,  0.62042875]), array([ 0.73362832,  0.4939759 ]), array([ 0.67316281,  0.55002795]), array([3390, 2988], dtype=int64))

Manual  2  fold cross validation score
cross_validation.py:21: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  x_cv = x_train[sIndex:fIndex]
cross_validation.py:22: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  y_cv = y_train[sIndex:fIndex]
cross_validation.py:24: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  x_t = np.concatenate((x_train[0:max(0,sIndex)],x_train[fIndex:n]),axis=0);
cross_validation.py:25: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  y_t = np.concatenate((y_train[0:max(0,sIndex)],y_train[fIndex:n]),axis=0);
0.598270243169
0.609989972424

Checking with inbuilt function
[ 0.59601404  0.61606919]

Manual parameter tuning
Tuning no. of estimators
Score for  10 : 0.62041392286
Score for  20 : 0.632800250862
Score for  30 : 0.640012543117
Score for  40 : 0.647381624334
Score for  50 : 0.652398871119
Score for  60 : 0.658043273754
Score for  70 : 0.651614926309
Score for  80 : 0.649890247727
Score for  90 : 0.655534650361
Score for  100 : 0.656632173095
Score for  110 : 0.656632173095
Best parameter :  60

Tuning max depth
Score for  5 : 0.641266854813
Score for  10 : 0.654907494512
Score for  15 : 0.658200062716
Score for  20 : 0.653653182816
Score for  25 : 0.64863593603
Best parameter :  15

Max score obtained using decision tree :  0.658200062716

--All

Score :  0.628096582001
Precision recall f-score support :  (array([ 0.62469378,  0.63414634]), array([ 0.75221239,  0.48728246]), array([ 0.68254818,  0.55109765]), array([3390, 2988], dtype=int64))

Manual  2  fold cross validation score
cross_validation.py:21: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  x_cv = x_train[sIndex:fIndex]
cross_validation.py:22: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  y_cv = y_train[sIndex:fIndex]
cross_validation.py:24: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  x_t = np.concatenate((x_train[0:max(0,sIndex)],x_train[fIndex:n]),axis=0);
cross_validation.py:25: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  y_t = np.concatenate((y_train[0:max(0,sIndex)],y_train[fIndex:n]),axis=0);
0.593695161695
0.617824016044

Checking with inbuilt function
[ 0.59833292  0.61537979]

Manual parameter tuning
Tuning no. of estimators
Score for  10 : 0.632016306052
Score for  20 : 0.650360614613
Score for  30 : 0.644559423017
Score for  40 : 0.655221072437
Score for  50 : 0.660551897146
Score for  60 : 0.656945751019
Score for  70 : 0.659454374412
Score for  80 : 0.666666666667
Score for  90 : 0.659611163374
Score for  100 : 0.662276575729
Score for  110 : 0.663217309501
Best parameter :  80

Tuning max depth
Score for  5 : 0.650517403575
Score for  10 : 0.664314832236
Score for  15 : 0.669332079022
Score for  20 : 0.662746942615
Score for  25 : 0.65851364064
Best parameter :  15

Max score obtained using decision tree :  0.669332079022